{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO+ZgA3KByNHQ5Zjny+N/yE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Importing the libraries"],"metadata":{"id":"c1rqRS-5rA6d"}},{"cell_type":"code","execution_count":3,"metadata":{"id":"jgUjJQfbqI-t","executionInfo":{"status":"ok","timestamp":1733366211994,"user_tz":-330,"elapsed":352,"user":{"displayName":"Meghana Narvekar","userId":"06351379999402519709"}}},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"code","source":["tf.__version__"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"gqHHPnQNrIVV","executionInfo":{"status":"ok","timestamp":1733366167050,"user_tz":-330,"elapsed":355,"user":{"displayName":"Meghana Narvekar","userId":"06351379999402519709"}},"outputId":"5d73f058-590d-4be8-9d93-153b518cf10a"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.17.1'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["train_datagen = ImageDataGenerator(rescale = 1./255,\n","                                   shear_range = 0.2,\n","                                   zoom_range = 0.2,\n","                                   horizontal_flip = True)\n","training_set = train_datagen.flow_from_directory('C:\\Users\\admin\\Downloads\\small_dataset\\small_dataset\\training_set',\n","                                                 target_size = (64, 64),\n","                                                 batch_size = 32,\n","                                                 class_mode = 'binary')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":106},"id":"wx3YUCrprOkc","executionInfo":{"status":"error","timestamp":1733367195775,"user_tz":-330,"elapsed":379,"user":{"displayName":"Meghana Narvekar","userId":"06351379999402519709"}},"outputId":"8d381503-c449-40d1-dee5-6f2b0facfe3d"},"execution_count":4,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (<ipython-input-4-0ec6864a9526>, line 5)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-0ec6864a9526>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    training_set = train_datagen.flow_from_directory('C:\\Users\\admin\\Downloads\\small_dataset\\small_dataset\\training_set',\u001b[0m\n\u001b[0m                                                                                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"]}]},{"cell_type":"markdown","source":["preprocessing the test set"],"metadata":{"id":"PNWfoyHUsXiN"}},{"cell_type":"code","source":["test_datagen = ImageDataGenerator(rescale = 1./255)\n","test_set = test_datagen.flow_from_directory('C:\\Users\\admin\\Downloads\\small_dataset\\small_dataset\\test_set',\n","                                            target_size = (64, 64),\n","                                            batch_size = 32,\n","                                            class_mode = 'binary')"],"metadata":{"id":"4jsT3HSCsaEk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Initialising the CNN"],"metadata":{"id":"bqvnsdO6wwKj"}},{"cell_type":"code","source":["cnn = tf.keras.models.Sequential()"],"metadata":{"id":"lY6G2KeIw1Za"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["step1 - convolution"],"metadata":{"id":"J-0ckqZExDRy"}},{"cell_type":"code","source":["cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))"],"metadata":{"id":"gvl4k4NjxH5a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["step2 - pooling"],"metadata":{"id":"QJ2EblhLxn46"}},{"cell_type":"code","source":["cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"],"metadata":{"id":"wAAetSJWx6dy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["adding a second convolution layer"],"metadata":{"id":"UzaS-iFbx9vq"}},{"cell_type":"code","source":["cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n","cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"],"metadata":{"id":"SeLCLtCoyBbi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["step3 - flattening"],"metadata":{"id":"KNU9_F49y0cK"}},{"cell_type":"code","source":["cnn.add(tf.keras.layers.Flatten)"],"metadata":{"id":"IsrO7yTnzH-C"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["step4- full connectiion"],"metadata":{"id":"SJIeDI-bzYrB"}},{"cell_type":"code","source":["cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"],"metadata":{"id":"6XFv74HMzc1S"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["step5 - ouput layer"],"metadata":{"id":"4EmLGqMJzw5x"}},{"cell_type":"code","source":["cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"],"metadata":{"id":"b7tGJzzYz0DK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["compiling the cnn"],"metadata":{"id":"qLXugPqf0UmB"}},{"cell_type":"code","source":["cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"],"metadata":{"id":"5HSy1DJH0XuB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["training the cnn on the training set and evaluating it on the test set\n","if error comes\n","import scipy\n","import pprint\n","import numpy as np\n","import scipy.ndimage\n","print(scipy.version.version)"],"metadata":{"id":"87Rp0a760rjZ"}},{"cell_type":"code","source":["cnn.fit(x = training_set, validation_data = test_set, epochs = 25 )"],"metadata":{"id":"PBpYuasd0yYB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["part4 making a single prediction"],"metadata":{"id":"cKQ28Omz1BPp"}},{"cell_type":"code","source":["import numpy as np\n","from keras.preprocessing import image\n","test_image = image.load_img('C:\\Users\\admin\\Downloads\\small_dataset\\small_dataset\\single_prediction\\cat_or_dog_1.jpg', target_size = (64, 64))\n","test_image = image.img_to_array(test_image)\n","test_image = np.expand_dims(test_image, axis = 0)\n","result = cnn.predict(test_image)\n","training_set.class_indices\n","if result[0][0] == 1:\n","  prediction = 'dog'\n","else:\n","  prediction = 'cat'"],"metadata":{"id":"AFxq7N8a1Epw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(prediction)"],"metadata":{"id":"xmYjAEra8s8v"},"execution_count":null,"outputs":[]}]}